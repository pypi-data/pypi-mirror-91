{
    "name": "keras.preprocessing.text.Tokenizer",
    "contributors": [
        "Carles Sala <csala@csail.mit.edu>"
    ],
    "documentation": "https://keras.io/preprocessing/text/#tokenizer",
    "description": "Text tokenization utility class.",
    "classifiers": {
        "type": "preprocessor",
        "subtype": "feature_extractor"
    },
    "modalities": [
        "text"
    ],
    "primitive": "keras.preprocessing.text.Tokenizer",
    "fit": {
        "method": "fit_on_texts",
        "args": [
            {
                "name": "X",
                "keyword": "texts",
                "description": "list of strings, or list of list of strings.",
                "type": "list"
            }
        ]
    },
    "produce": {
        "method": "texts_to_sequences",
        "args": [
            {
                "name": "X",
                "keyword": "texts",
                "description": "list of strings, or list of list of strings.",
                "type": "list"
            }
        ],
        "output": [
            {
                "name": "X",
                "description": "list of sequences",
                "type": "list"
            }
        ]
    },
    "hyperparameters": {
        "fixed": {
            "filters": {
                "type": "str",
                "default": "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\n"
            },
            "split": {
                "type": "str",
                "default": " "
            },
            "oov_token": {
                "type": "str",
                "default": null
            }
        },
        "tunable": {
            "num_words": {
                "type": "int",
                "default": null,
                "range": [
                    1,
                    10000
                ]
            },
            "lower": {
                "type": "bool",
                "default": true
            },
            "char_level": {
                "type": "bool",
                "default": false
            }
        }
    }
}
