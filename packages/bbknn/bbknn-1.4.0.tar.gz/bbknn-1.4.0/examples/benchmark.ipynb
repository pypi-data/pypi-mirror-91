{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run benchmarking for all the methods. Do it within R, as both Scanorama and BBKNN are responsive to reticulate, and this way I don't have to rpy2 over gigantic Splatter count matrices.\n",
    "\n",
    "Import the python stuff first, as Scanorama is a primadonna and refuses to load if it comes after the R block below because reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)\n",
    "use_python('/Users/kp9/anaconda3/envs/orig/bin/python')\n",
    "bbknn = import('bbknn')\n",
    "scanorama = import('scanorama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: SingleCellExperiment\n",
      "Loading required package: SummarizedExperiment\n",
      "Loading required package: GenomicRanges\n",
      "Loading required package: stats4\n",
      "Loading required package: BiocGenerics\n",
      "Loading required package: parallel\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "The following objects are masked from ‘package:parallel’:\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colMeans,\n",
      "    colnames, colSums, dirname, do.call, duplicated, eval, evalq,\n",
      "    Filter, Find, get, grep, grepl, intersect, is.unsorted, lapply,\n",
      "    lengths, Map, mapply, match, mget, order, paste, pmax, pmax.int,\n",
      "    pmin, pmin.int, Position, rank, rbind, Reduce, rowMeans, rownames,\n",
      "    rowSums, sapply, setdiff, sort, table, tapply, union, unique,\n",
      "    unsplit, which, which.max, which.min\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    expand.grid\n",
      "\n",
      "Loading required package: IRanges\n",
      "Loading required package: GenomeInfoDb\n",
      "Loading required package: Biobase\n",
      "Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "Loading required package: DelayedArray\n",
      "Loading required package: matrixStats\n",
      "\n",
      "Attaching package: ‘matrixStats’\n",
      "\n",
      "The following objects are masked from ‘package:Biobase’:\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "Loading required package: BiocParallel\n",
      "\n",
      "Attaching package: ‘DelayedArray’\n",
      "\n",
      "The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    colMaxs, colMins, colRanges, rowMaxs, rowMins, rowRanges\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    aperm, apply\n",
      "\n",
      "Loading required package: Rcpp\n",
      "Loading required package: Matrix\n",
      "\n",
      "Attaching package: ‘Matrix’\n",
      "\n",
      "The following object is masked from ‘package:S4Vectors’:\n",
      "\n",
      "    expand\n",
      "\n",
      "Loading required package: ggplot2\n",
      "Loading required package: cowplot\n",
      "\n",
      "Attaching package: ‘cowplot’\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    ggsave\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(splatter)\n",
    "library(harmony)\n",
    "library(irlba)\n",
    "library(magrittr)\n",
    "library(scran)\n",
    "library(Seurat)\n",
    "library(RcppCNPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the algorithms on datasets with cell totals scaling up in powers of two. Start by running all the methods up to a total of 2^15 (~32,000) cells. The data is simulated via Splatter, split evenly into two batches, each of those with two cell types, with 5000 differentially expressed genes emulating a highly variable gene pool. Not like the actual numeric content is of much relevance here, but may as well keep it proper.\n",
    "\n",
    "Note the `use_faiss = FALSE` in BBKNN. For some reason, faiss is not happy with being ran via this particular reticulate setup. It's going to be benchmarked separately in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 10\n",
      "[1] 6.228694\n",
      "[1] 76.0922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 97.57821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 149 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 78 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 75 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 45 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 35 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 24 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 16 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 17 iterations\n",
      "[1] 8.485609\n",
      "[1] 0.2886209\n",
      "[1] 0.29918\n",
      "[1] 11\n",
      "[1] 12.72698\n",
      "[1] 250.6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 163.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 133 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 63 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 41 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 28 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 26 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 15 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n",
      "[1] 12.75697\n",
      "[1] 0.727396\n",
      "[1] 0.4967551\n",
      "[1] 12\n",
      "[1] 31.04822\n",
      "[1] 924.8357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 314.9184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 158 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 51 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 33 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 15 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n",
      "[1] 29.8317\n",
      "[1] 2.040226\n",
      "[1] 0.9200101\n",
      "[1] 13\n",
      "[1] 70.94677\n",
      "[1] 3636.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 730.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 109 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 20 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n",
      "Harmony converged after 8 iterations\n",
      "\n",
      "[1] 54.75862\n",
      "[1] 5.953090\n",
      "[1] 1.787516\n",
      "[1] 14\n",
      "[1] 160.7911\n",
      "[1] 13138.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n",
      "Scaling data matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2688.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 106 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 20 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n",
      "Harmony converged after 5 iterations\n",
      "\n",
      "[1] 108.129\n",
      "[1] 28.7195\n",
      "[1] 4.139049\n"
     ]
    }
   ],
   "source": [
    "scanorama_time = c()\n",
    "mnn_time = c()\n",
    "cca_time = c()\n",
    "harmony_time = c()\n",
    "bbknn_time = c()\n",
    "annoy_time = c()\n",
    "\n",
    "for (i in 10:14)\n",
    "{\n",
    "    print(i)\n",
    "    \n",
    "    #prepare splatter data\n",
    "    params = newSplatParams()\n",
    "    params = setParam(params, \"nGenes\", 5000)\n",
    "    params = setParam(params, \"de.prob\", 1)\n",
    "    params = setParam(params, \"batchCells\", c(2^i,2^i))\n",
    "    params = setParam(params, \"group.prob\", c(0.5,0.5))\n",
    "    sim = splatSimulate(params, method=\"groups\", verbose=FALSE)\n",
    "    \n",
    "    #data prep for scanorama\n",
    "    counts = list()\n",
    "    counts[[1]] = t(counts(sim)[,1:(2^i)])\n",
    "    counts[[2]] = t(counts(sim)[,(2^i+1):(2^(i+1))])\n",
    "    genes = list()\n",
    "    genes[[1]] = 1:5000\n",
    "    genes[[2]] = 1:5000\n",
    "    #run scanorama\n",
    "    t1 = Sys.time()\n",
    "    corrected = scanorama$correct(counts,genes)\n",
    "    t2 = Sys.time()\n",
    "    scanorama_time = c(scanorama_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(scanorama_time,n=1))\n",
    "    \n",
    "    #repurpose scanorama input for mnncorrect \n",
    "    counts[[1]] = t(counts[[1]])\n",
    "    counts[[2]] = t(counts[[2]])\n",
    "    #run mnncorrect\n",
    "    t1 = Sys.time()\n",
    "    mnn = mnnCorrect(counts[[1]], counts[[2]], BPPARAM=MulticoreParam(detectCores()))\n",
    "    t2 = Sys.time()\n",
    "    mnn_time = c(mnn_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(mnn_time,n=1))\n",
    "    \n",
    "    #prepare Seurat stuff\n",
    "    srat = CreateSeuratObject(raw.data = counts(sim))\n",
    "    srat = NormalizeData(object = srat, normalization.method = \"LogNormalize\", scale.factor = 10000)\n",
    "    srat@var.genes = rownames(srat@data)\n",
    "    srat = ScaleData(object = srat)\n",
    "    srat@meta.data[,'Batch'] = colData(sim)[,'Batch']\n",
    "    #and then it needs to be split so that CCA can see it\n",
    "    srat1 = SubsetData(srat, subset.name='Batch', accept.value='Batch1')\n",
    "    srat2 = SubsetData(srat, subset.name='Batch', accept.value='Batch2')\n",
    "    #run CCA\n",
    "    t1 = Sys.time()\n",
    "    srat = RunCCA(srat1, srat2, num.cc=20)\n",
    "    srat = AlignSubspace(srat, reduction.type='cca', grouping.var='Batch', dims.align=1:20)\n",
    "    t2 = Sys.time()\n",
    "    cca_time = c(cca_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(cca_time,n=1))\n",
    "    \n",
    "    #extract batch vector\n",
    "    batch = colData(sim)[,'Batch']\n",
    "    #run irlba PCA\n",
    "    pca = irlba(A=counts(sim),nv=50)\n",
    "    pca = pca$v\n",
    "    #run harmony\n",
    "    t1 = Sys.time()\n",
    "    hem = HarmonyMatrix(pca, batch)\n",
    "    t2 = Sys.time()\n",
    "    harmony_time = c(harmony_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(harmony_time,n=1))\n",
    "    \n",
    "    #run BBKNN with cKDTree neighbours\n",
    "    t1 = Sys.time()\n",
    "    bem = bbknn$bbknn_pca_matrix(pca = pca, batch_list = batch, approx = FALSE, use_faiss = FALSE)\n",
    "    t2 = Sys.time()\n",
    "    bbknn_time = c(bbknn_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(bbknn_time,n=1))\n",
    "    #run BBKNN with approximate neighbours\n",
    "    t1 = Sys.time()\n",
    "    bem = bbknn$bbknn_pca_matrix(pca = pca, batch_list = batch)\n",
    "    t2 = Sys.time()\n",
    "    annoy_time = c(annoy_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(annoy_time,n=1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir.create('benchmark-times',showWarnings = FALSE)\n",
    "fid = file('benchmark-times/scanorama.txt')\n",
    "writeLines(as.character(scanorama_time),fid)\n",
    "close(fid)\n",
    "fid = file('benchmark-times/mnn.txt')\n",
    "writeLines(as.character(mnn_time),fid)\n",
    "close(fid)\n",
    "fid = file('benchmark-times/cca.txt')\n",
    "writeLines(as.character(cca_time),fid)\n",
    "close(fid)\n",
    "fid = file('benchmark-times/harmony.txt')\n",
    "writeLines(as.character(harmony_time),fid)\n",
    "close(fid)\n",
    "fid = file('benchmark-times/bbknn.txt')\n",
    "writeLines(as.character(bbknn_time),fid)\n",
    "close(fid)\n",
    "fid = file('benchmark-times/annoy.txt')\n",
    "writeLines(as.character(annoy_time),fid)\n",
    "close(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're entering big dataset land. Run Harmony and BBKNN, as Scanorama is resource intensive and dies on the very first of the larger datasets (possibly due to some overhead from being reticulated, don't know, but it's not happy). Shrink Splatter gene pool to 500 in the interest of resource efficiency - the actual gene count doesn't matter in the slightest for run time benchmarking of these two, as they both operate on PCA space. Just in case, write out run times after each loop iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 78 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 22 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n",
      "Harmony converged after 5 iterations\n",
      "\n",
      "[1] 211.84\n",
      "[1] 141.256\n",
      "[1] 7.87409\n",
      "[1] 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 81 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 19 iterations\n",
      "Harmony converged after 4 iterations\n",
      "\n",
      "[1] 479.0176\n",
      "[1] 522.1306\n",
      "[1] 15.69402\n",
      "[1] 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 75 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 20 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 12 iterations\n",
      "Harmony converged after 5 iterations\n",
      "\n",
      "[1] 1218.27\n",
      "[1] 2538.578\n",
      "[1] 31.73074\n",
      "[1] 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/10\n",
      "Harmony 2/10\n",
      "Harmony 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 71 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered for 17 iterations\n",
      "Harmony converged after 4 iterations\n",
      "\n",
      "[1] 2484.623\n",
      "[1] 13600.3\n",
      "[1] 65.80895\n"
     ]
    }
   ],
   "source": [
    "for (i in 15:18)\n",
    "{\n",
    "    print(i)\n",
    "    \n",
    "    #prepare splatter data\n",
    "    params = newSplatParams()\n",
    "    params = setParam(params, \"nGenes\", 500)\n",
    "    params = setParam(params, \"de.prob\", 1)\n",
    "    params = setParam(params, \"batchCells\", c(2^i,2^i))\n",
    "    params = setParam(params, \"group.prob\", c(0.5,0.5))\n",
    "    sim = splatSimulate(params, method=\"groups\", verbose=FALSE)\n",
    "    \n",
    "    #extract batch vector\n",
    "    batch = colData(sim)[,'Batch']\n",
    "    #run irlba PCA\n",
    "    pca = irlba(A=counts(sim),nv=50)\n",
    "    pca = pca$v\n",
    "    #run harmony\n",
    "    t1 = Sys.time()\n",
    "    hem = HarmonyMatrix(pca, batch)\n",
    "    t2 = Sys.time()\n",
    "    harmony_time = c(harmony_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(harmony_time,n=1))\n",
    "    \n",
    "    #run BBKNN with cKDTree neighbours\n",
    "    t1 = Sys.time()\n",
    "    bem = bbknn$bbknn_pca_matrix(pca = pca, batch_list = batch, approx = FALSE, use_faiss = FALSE)\n",
    "    t2 = Sys.time()\n",
    "    bbknn_time = c(bbknn_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(bbknn_time,n=1))\n",
    "    #run BBKNN with approximate neighbours\n",
    "    t1 = Sys.time()\n",
    "    bem = bbknn$bbknn_pca_matrix(pca = pca, batch_list = batch)\n",
    "    t2 = Sys.time()\n",
    "    annoy_time = c(annoy_time, as.numeric(difftime(t2,t1,units='secs')))\n",
    "    print(tail(annoy_time,n=1))\n",
    "    \n",
    "    #write output, in case something goes south\n",
    "    fid = file('benchmark-times/harmony.txt')\n",
    "    writeLines(as.character(harmony_time),fid)\n",
    "    close(fid)\n",
    "    fid = file('benchmark-times/bbknn.txt')\n",
    "    writeLines(as.character(bbknn_time),fid)\n",
    "    close(fid)\n",
    "    fid = file('benchmark-times/annoy.txt')\n",
    "    writeLines(as.character(annoy_time),fid)\n",
    "    close(fid)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whatever reason, faiss just doesn't seem to get along with R at all - trying to rpy2 in some Splatter data makes it fail as well. As such, let's generate the PCAs to run faiss on from within this R notebook, and then import them into Python and feed them to faiss. In retrospect, I could have saved them as I made them while benchmarking previously, but I did not foresee faiss being quite this picky with regards to R and the benchmark itself sure took a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i in 10:18)\n",
    "{\n",
    "    #prepare splatter data\n",
    "    params = newSplatParams()\n",
    "    params = setParam(params, \"nGenes\", 500)\n",
    "    params = setParam(params, \"de.prob\", 1)\n",
    "    params = setParam(params, \"batchCells\", c(2^i,2^i))\n",
    "    params = setParam(params, \"group.prob\", c(0.5,0.5))\n",
    "    sim = splatSimulate(params, method=\"groups\", verbose=FALSE)\n",
    "\n",
    "    #run irlba PCA\n",
    "    pca = irlba(A=counts(sim),nv=50)\n",
    "    pca = pca$v\n",
    "    \n",
    "    #save pickle\n",
    "    npySave(paste('pca',i,'.npy',sep=''),pca)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
