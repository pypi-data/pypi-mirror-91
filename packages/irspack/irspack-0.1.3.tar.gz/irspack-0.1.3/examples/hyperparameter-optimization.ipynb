{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "In this tutorial, we optimize `P3alphaRecommender`'s performance by our [optuna](https://github.com/optuna/optuna)-backed `P3alphaOptimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from irspack.dataset.movielens import MovieLens1MDataManager\n",
    "from irspack.recommenders import P3alphaRecommender\n",
    "from irspack.optimizers import P3alphaOptimizer\n",
    "from irspack.split import rowwise_train_test_split\n",
    "from irspack.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comptutation might be heavy, so we use multiple threads to speed up the training and evaluation.\n",
    "\n",
    "You can tell our algorithms to use mutiple threads whenever possible by setting ``IRSPACK_NUM_THREADS_DEFAULT`` environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"IRSPACK_NUM_THREADS_DEFAULT\"] = \"8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the ML1M dataset again.\n",
    "\n",
    "We again prepare the sparse matrix `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MovieLens1MDataManager()\n",
    "\n",
    "df = loader.read_interaction()\n",
    "\n",
    "movies = loader.read_item_info()\n",
    "movies.head()\n",
    "\n",
    "unique_user_ids, user_index = np.unique(df.userId, return_inverse=True)\n",
    "unique_movie_ids, movie_index = np.unique(df.movieId, return_inverse=True)\n",
    "\n",
    "movie_id_vs_movie_index = { mid: i for i, mid in enumerate(unique_movie_ids)}\n",
    "\n",
    "X = sps.csr_matrix(\n",
    "    (\n",
    "        np.ones(df.shape[0]),\n",
    "        ( user_index, movie_index)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split scheme 2. Hold-out for partial users.\n",
    "\n",
    "To perform the hyperparameter optimization, we have to repeatedly measure the accuracy metrics on the validation set. As mentioned in the previous tutorial, doing this for all users is time-comsuming (often heavier than the recommender's learning process), so we truncate this subset as follows:\n",
    "\n",
    "1. First split **users** into \"train\", \"validation\" (and \"test\") ones.\n",
    "1. For train users, feed all their interactions into the recommender. For validation (test) users, hold-out part of their interaction for the validation (\"prediction\" part), and feed the rest (\"learning\" part) into the recommender.\n",
    "1. After the fit, ask the recommender to output the score only for validation (test) users, and see how it ranks these held-out interactions for the validation (test) users.\n",
    "\n",
    "![Perform hold out for part of users.](./split2.png \"split1\")\n",
    "\n",
    "Although we have prepared another function to do this procedure, let us first do this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split users into train and validation users.\n",
    "\n",
    "X_train_user, X_valid_user = train_test_split(X, test_size=.4, random_state=0)\n",
    "\n",
    "# Split the validation users' interaction into learning 50% and predcition 50%.\n",
    "\n",
    "X_valid_learn, X_valid_predict = rowwise_train_test_split(\n",
    "    X_valid_user, test_ratio=.5, random_seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the evaluator and optimize the validation metric\n",
    "\n",
    "As illustrated above, we will use \n",
    "\n",
    " * Train users' all interactions (``X_train_user``)\n",
    " * Validation users' 50% interaction (``X_valid_learn``)\n",
    " \n",
    "as the recommender's training resource, and validation users' rest interaction (``X_valid_predict``) as the held-out ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_learn = sps.vstack([X_train_user, X_valid_learn])\n",
    "evaluator = Evaluator(X_valid_predict, offset=X_train_user.shape[0], cutoff=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``offset`` parameter specifies where the validation user block begins (where the train user block ends).\n",
    "\n",
    "Now to start the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = P3alphaOptimizer(X_train_val_learn, evaluator, metric=\"ndcg\")\n",
    "best_params, validation_results = optimizer.optimize(random_seed=0, n_trials=20)\n",
    "# stdout has been truncated as it's too lengthy to show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here are the results of the optimization. \n",
    "\n",
    "The best `ndcg@20` value has been obtained by using these hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 5.063313369473015e-07, 'top_k': 161, 'normalize_weight': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the resulting ndcg value is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5190536602989886"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results.ndcg.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, the default argument of ``P3alphaRecommdner`` (which has been used so far)\n",
    "attains `ndcg@20` = 0.404. So this is indeed a significant improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4041442008349765"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_default = P3alphaRecommender(X_train_val_learn).learn()\n",
    "evaluator.get_score(rec_default)['ndcg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the recommender's output again\n",
    "\n",
    "Let us finally check how our recommender has evolved from the first tutorial.\n",
    "\n",
    "We consider the same setting (a new user has watched \"Toy Story\"), but fit the \n",
    "recommender using the obtained parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_tuned = P3alphaRecommender(X, **best_params).learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>Groundhog Day (1993)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>Shakespeare in Love (1998)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "      <td>Comedy|Sci-Fi</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Saving Private Ryan (1998)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Babe (1995)</td>\n",
       "      <td>Children's|Comedy|Drama</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>Comedy|Romance|War</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>Princess Bride, The (1987)</td>\n",
       "      <td>Action|Adventure|Comedy|Romance</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Aladdin (1992)</td>\n",
       "      <td>Animation|Children's|Comedy|Musical</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title                               genres  \\\n",
       "movieId                                                                    \n",
       "1265           Groundhog Day (1993)                       Comedy|Romance   \n",
       "2396     Shakespeare in Love (1998)                       Comedy|Romance   \n",
       "3114             Toy Story 2 (1999)          Animation|Children's|Comedy   \n",
       "1270      Back to the Future (1985)                        Comedy|Sci-Fi   \n",
       "2028     Saving Private Ryan (1998)                     Action|Drama|War   \n",
       "34                      Babe (1995)              Children's|Comedy|Drama   \n",
       "356             Forrest Gump (1994)                   Comedy|Romance|War   \n",
       "2355           Bug's Life, A (1998)          Animation|Children's|Comedy   \n",
       "1197     Princess Bride, The (1987)      Action|Adventure|Comedy|Romance   \n",
       "588                  Aladdin (1992)  Animation|Children's|Comedy|Musical   \n",
       "\n",
       "         release_year  \n",
       "movieId                \n",
       "1265             1993  \n",
       "2396             1998  \n",
       "3114             1999  \n",
       "1270             1985  \n",
       "2028             1998  \n",
       "34               1995  \n",
       "356              1994  \n",
       "2355             1998  \n",
       "1197             1987  \n",
       "588              1992  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toystory_id = 1\n",
    "toystory_watcher_matrix = sps.csr_matrix(\n",
    "    ([1], ([0], [movie_id_vs_movie_index[toystory_id]])),\n",
    "    shape=(1, len(unique_movie_ids)) # this time\n",
    ")\n",
    "\n",
    "score = rec_tuned.get_score_cold_user_remove_seen(\n",
    "    toystory_watcher_matrix\n",
    ")\n",
    "\n",
    "recommended_movie_index = score[0].argsort()[::-1][:10]\n",
    "recommended_movie_ids = unique_movie_ids[recommended_movie_index]\n",
    "\n",
    "# Top-10 recommendations\n",
    "movies.reindex(recommended_movie_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how drastically the recommended contents have changed (increased significance of genre \"Children's\" and disapperance of \"Star Wars\" series, etc...)!\n",
    "\n",
    "To be complete, we should\n",
    "\n",
    "* include other algorithms\n",
    "* measure the final score against **test** dataset, not validation\n",
    "\n",
    "but these are now straightforward. See our `examples/movielens/` directories for these complete examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
