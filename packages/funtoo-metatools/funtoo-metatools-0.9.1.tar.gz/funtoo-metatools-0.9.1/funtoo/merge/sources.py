#!/usr/bin/env python3

import logging
from collections import defaultdict
from concurrent.futures import as_completed
from concurrent.futures.thread import ThreadPoolExecutor

hub = None


def __init__():
	hub.CURRENT_SOURCE_DEF = None
	hub.SOURCE_REPOS = {}


def initialize_repo(repo_dict):
	print("Going to initialize", repo_dict)
	repo_name = repo_dict["name"]
	repo_url = repo_dict["url"]
	repo_key = repo_name
	repo_branch = repo_dict["branch"] if "branch" in repo_dict else "master"
	repo_sha1 = repo_dict["src_sha1"] if "src_sha1" in repo_dict else None
	if repo_key in hub.SOURCE_REPOS:
		repo_obj = hub.SOURCE_REPOS[repo_key]
		if repo_sha1:
			repo_obj.gitCheckout(sha1=repo_sha1)
		elif repo_branch:
			repo_obj.gitCheckout(branch=repo_branch)
	else:
		path = repo_name
		repo_obj = hub.merge.tree.GitTree(
			repo_name,
			url=repo_url,
			root="%s/%s" % (hub.MERGE_CONFIG.source_trees, path),
			branch=repo_branch,
			commit_sha1=repo_sha1,
			origin_check=False,
			reclone=False,
		)
		repo_obj.initialize()
		hub.SOURCE_REPOS[repo_key] = repo_obj


async def initialize_sources(source):
	if hub.CURRENT_SOURCE_DEF == source:
		return
	repos = list(hub.merge.foundations.get_repos(source))
	repo_futures = []
	with ThreadPoolExecutor(max_workers=8) as executor:
		for repo_dict in repos:
			fut = executor.submit(initialize_repo, repo_dict)
			repo_futures.append(fut)
	for repo_fut in as_completed(repo_futures):
		continue
	hub.CURRENT_SOURCE_DEF = source


def get_kits_in_correct_processing_order():

	"""
	Kits should be processed in a certain order. In the old days, this was done linearly, one at a time.
	In the new code base, we support multi-threading, so things can run in parallel. But there are still
	rules. Here's how the new system works:

	1. core-kit gets processed (generated) first. This is because it contains the official set of
	   eclasses and we need this set of eclasses for generation of the metadata cache for all the
	   other kits.

	2. Then, we order kits into 'pipelines'. All the kits in a pipeline can run in parallel.

	This function returns two objects. The first is a list called `pipeline_keys`. This is a list of
	names of pipelines, and the pipelines should be processed in the order listed in
	`pipeline_keys`. `core-kit` is in its own pipeline by itself so it gets processed first.

	The second variable returned is a dictionary called `pipelines` which maps the pipeline name to a
	list of kits. Actually, a list of kit-dict definitions (YAML definitions).
	"""

	# Rules:
	#
	# 1. If kits don't have the same source definitions (source repos), they can't be in the same
	#    thread-group.
	#
	# 2. If kits have the same name but different branches, they can't be in the same thread group
	#    (We can't have two threads messing with the same git repo at the same time.)
	#
	# 3. Core-kit must be processed first and have only one branch defined.
	#
	# 4. Independent kits can be processed all at once and have no source repos. (but see rule 2 which still applies.)

	kit_pipeline_keys = ["core-kit"]
	kit_pipeline_slots = defaultdict(list)
	pipeline_count = 0

	def find_existing_pipeline(kit_dict):
		"""
		For threading, we want to group kits into collections (pipelines) when they can legally run at the same
		time. This function will help us find a pipeline which we can "legally" join. If we can't find an existing
		pipeline that works for us, this function will return None so we can know to create a new thread pipeline.
		"""

		for pipeline_key in kit_pipeline_keys[1:]:
			skip_pipeline = False
			for item in kit_pipeline_slots[pipeline_key]:
				if kit_dict["kind"] == "autogenerated" and "source" in item and item["source"] != kit_dict["source"]:
					# Autogenerated kit different git sources, can't use this pipeline:
					skip_pipeline = True
					break
				elif item["name"] == kit_dict["name"]:
					# already processing another branch of same kit in this pipeline, so can't run simultaneously:
					skip_pipeline = True
					break
			if skip_pipeline:
				continue
			return pipeline_key
		return None

	for kit_dict in hub.KIT_GROUPS:
		if kit_dict["name"] == "core-kit":
			if len(kit_pipeline_slots["core-kit"]):
				raise ValueError("You must only define one core-kit in your kit groups.")
			kit_pipeline_slots["core-kit"].append(kit_dict)
		else:
			pipeline_key = find_existing_pipeline(kit_dict)
			if pipeline_key is None:
				pipeline_key = f"pipeline{pipeline_count}"
				pipeline_count += 1
				kit_pipeline_keys.append(pipeline_key)
			kit_pipeline_slots[pipeline_key].append(kit_dict)

	logging.info(f"{len(kit_pipeline_keys)} pipelines generated:")
	for key in kit_pipeline_keys:
		logging.info(f" == {key}")
		for kit_dict in kit_pipeline_slots[key]:
			logging.info(f"  * {kit_dict['name']} / {kit_dict['branch']} / {kit_dict['kind']}")
	return kit_pipeline_keys, kit_pipeline_slots
