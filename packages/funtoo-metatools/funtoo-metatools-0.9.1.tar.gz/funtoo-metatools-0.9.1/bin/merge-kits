#!/usr/bin/env python3
import argparse
import asyncio
import sys
from collections import defaultdict, OrderedDict
from concurrent.futures import as_completed
from concurrent.futures.thread import ThreadPoolExecutor
from datetime import datetime

from dict_tools.data import NamespaceDict
from merge_utils.hub import Hub


class MergeError(Exception):
	pass


async def main_thread():

	# Before we start looking at YAML, we need to ensure our two critical source repos are checked out

	hub.META_REPO.initialize()
	hub.FIXUP_REPO.initialize()
	hub.merge.metadata.cleanup_error_logs()

	hub.KIT_GROUPS = list(hub.merge.foundations.kit_groups())

	if not hub.merge.foundations.release_exists(hub.RELEASE):
		print(f"Release not found: {hub.RELEASE}.")
		sys.exit(1)

	# We want to delete all locally-cloned independent kits before we start processing, so we re-clone them to get
	# pristine copies with the latest commits (see FL-7935):

	hub.merge.kit.wipe_indy_kits()

	thread_keys, thread_groups = hub.merge.sources.get_kits_in_correct_processing_order()

	hub.KIT_RESULTS = OrderedDict()
	hub.KIT_SHA1S = defaultdict(dict)

	# This will generate core-kit, as well as all other kits:
	for source in thread_keys:
		kit_dict_list = thread_groups[source]
		regen_futures = []
		with ThreadPoolExecutor(max_workers=4) as executor:

			# Initialize sources based on the settings of the first kit in the group (they are all identical)
			kit_dict = kit_dict_list[0]

			if kit_dict["kind"] != "independent":
				# This initializes the "source repos" that are used to grab catpkgs from to generate this kit:
				await hub.merge.sources.initialize_sources(kit_dict["source"])

			for kit_dict in kit_dict_list:
				# For simplicity, set up a context variable to pass around, where ctx.kit contains the kit information:
				ctx = NamespaceDict()
				ctx["kit"] = NamespaceDict(kit_dict)
				# hub.merge.kit.generate_kit does the real work:
				future = executor.submit(hub.pkgtools.thread.run_async_adapter, hub.merge.kit.generate_kit, ctx)
				regen_futures.append(future)
			for future in as_completed(regen_futures):
				ctx, tree_obj, tree_sha1 = future.result()
				hub.KIT_RESULTS[ctx.kit.name] = (ctx, tree_obj, tree_sha1)
				hub.KIT_SHA1S[ctx.kit.name][ctx.kit.branch] = tree_sha1

	# Create meta-repo commit referencing our updated kits:
	hub.merge.kit.generate_metarepo_metadata(hub.KIT_SHA1S)
	hub.META_REPO.gitCommit(message="kit updates", skip=["kits"], push=hub.PUSH)

	if not hub.MIRROR:
		hub.merge.metadata.display_error_summary()
		return

	# Mirroring to GitHub happens here:

	kit_mirror_futures = []
	with ThreadPoolExecutor(max_workers=8) as executor:
		# Push all kits, then push meta-repo.
		for kit_name, kit_tuple in hub.KIT_RESULTS.items():
			ctx, tree_obj, tree_sha1 = kit_tuple
			future = executor.submit(hub.merge.kit.mirror_repository, tree_obj)
			kit_mirror_futures.append(future)
		for future in as_completed(kit_mirror_futures):
			kit_name = future.result()
			print(f"Mirroring of {kit_name} complete.")

	hub.merge.kit.mirror_repository(hub.META_REPO)
	print("Mirroring of meta-repo complete.")
	hub.merge.metadata.display_error_summary()


CLI_CONFIG = {
	"force": {"action": "store_true", "default": False},
	"nopush": {"action": "store_true", "default": False},
	"prod": {"action": "store_true", "default": False},
	"db": {"action": "store_true", "default": False},
	"release": {"positional": True},
}


def parse_args():
	ap = argparse.ArgumentParser()
	for arg, kwargs in CLI_CONFIG.items():
		if "os" in kwargs:
			del kwargs["os"]
		if "positional" in kwargs and kwargs["positional"]:
			new_kwargs = kwargs.copy()
			del new_kwargs["positional"]
			ap.add_argument(arg, **new_kwargs)
		else:
			ap.add_argument("--" + arg, **kwargs)
	return ap.parse_args()


if __name__ == "__main__":

	hub = Hub()
	hub.OPT = parse_args()

	# Parse options:

	push = not hub.OPT.nopush
	hub.PROD = prod = hub.OPT.prod
	forcepush = hub.OPT.force

	# Initialize internal pop globals that are expected to be in place when the merge sub gets added:

	hub.add("funtoo/merge", prod=prod, release=hub.OPT.release)
	hub.add("funtoo/pkgtools")

	if not prod:
		# This means we'll just generate our own local git trees for the purposes of generating kits. This is generally used by developers to see what
		# would end up in kits, when you don't really need to create any kits that will be used anywhere else.
		hub.GIT_CLASS = hub.merge.tree.AutoCreatedGitTree
		hub.GIT_CLASS_KWARGS_FN = None
		hub.PUSH = False
		hub.MIRROR = False
		hub.META_REPO = meta_repo = hub.GIT_CLASS(
			name="meta-repo", branch=hub.RELEASE, root=hub.MERGE_CONFIG.dest_trees + "/meta-repo"
		)
		hub.NEST_KITS = True
	else:

		# In this mode, we're actually wanting to update real kits, and likely are going to push our updates to remotes (unless --nopush is specified as an arg.)
		# This might be used by people generating their own custom kits for use on other systems, or by Funtoo itself for updating official kits and meta-repo.

		hub.NEST_KITS = False
		hub.PUSH = push
		hub.MIRROR = push
		hub.GIT_CLASS = hub.merge.tree.GitTree

		kwargs = {}
		if hub.MIRROR:
			kwargs["mirror"] = hub.MERGE_CONFIG.mirror.rstrip("/") + "/meta-repo"
		hub.META_REPO = meta_repo = hub.merge.tree.GitTree(
			"meta-repo",
			branch=hub.RELEASE,
			url=hub.MERGE_CONFIG.meta_repo,
			root=hub.MERGE_CONFIG.dest_trees + "/meta-repo",
			origin_check=True,
			**kwargs,
		)

	hub.START_TIME = datetime.utcnow()
	hub.FIXUP_REPO = hub.merge.tree.GitTree(
		"kit-fixups",
		hub.MERGE_CONFIG.branch("kit-fixups"),
		url=hub.MERGE_CONFIG.kit_fixups,
		root=hub.MERGE_CONFIG.source_trees + "/kit-fixups",
	)

	hub.CPM_LOGGER = None
	hub.LOOP.run_until_complete(main_thread())

	# if len(hub.METADATA_ERRORS):
	# 	print()
	# 	print("The following errors were encountered during processing:")
	# 	print()
	# 	for error in hub.METADATA_ERRORS:
	# 		print(f"{error.severity}: {error.ebuild_path}: {error.msg}")
	# 		if error.output:
	# 			print("Output: " + error.output)
	# 			print()

	sys.exit(0)

# vim: ts=4 sw=4 noet
