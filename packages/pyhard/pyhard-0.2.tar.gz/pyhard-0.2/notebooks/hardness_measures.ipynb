{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardness measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Código experimental\n",
    "---\n",
    "\n",
    "__Apenas para testar ideias e implementação das measures__\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ Pegar um dataset artificial bem conhecido. Gerei o dataset overlap em anexo.\n",
    "\n",
    "__2)__ Extrair, para cada instância do conjunto, meta-atributos de instance hardness. Em anexo seguem dois scripts em R com algumas medidas (tem as do artigo e uma outra que é do trabalho do José Luis). Segue em anexo também o TG do José Luis, as adaptações que ele fez estão descritas na Seção 3.4.\n",
    "\n",
    "__3)__ Rodar diferentes técnicas de classificação em 10-fold CV ou leave-one-out e extrair a medida de log-loss para cada instância (http://wiki.fast.ai/index.php/Log_Loss#Multi-class_Classification). Sugiro as técnicas: \n",
    "* SVM linear\n",
    "* SVM RBF\n",
    "* Random Forest\n",
    "* Gradient Boosting\n",
    "* Rede Neural MLP com uma camada\n",
    "* Bagging\n",
    "* Naïve Bayes\n",
    "* regressão logística\n",
    "\n",
    "__4)__ Montar um meta conjunto de dados em que cada linha é uma das instâncias do conjunto overlap e cada coluna é uma medida de instance hardness, seguidas de colunas que são os valores de log-loss de cada técnica. Tem uma convenção dos nomes que as colunas têm que ter para usar no Matilda depois (tem um exemplo de meta-conjunto de dados para o caixeiro viajante em https://matilda.unimelb.edu.au/matilda/matildadata/graph_coloring_problem/metadata/metadata.csv): \n",
    "\n",
    "_The CSV file must contain only 4 types of columns listed below. Column headers should strictly follow the required naming convention._\n",
    "\n",
    "i. _instances (instance identifier - We expect instance identifier to be of type \"String\". This column is mandatory)_\n",
    "\n",
    "ii. _Source (instance source - This column is optional)_\n",
    "\n",
    "iii. _feature_name (The keyword \"feature_\" concatenated with feature name. For instance, if feature name is \"density\", header name should be mentioned as \"feature_density\". If name consists of more than one word, each word should be separated by \"\\_\" (spaces are not allowed). You can add one or more features. This column is required either in \"Custom Problem\" or if you want to add more features in the analysis of a library problem.)_\n",
    "\n",
    "iv. _algo_name (The keyword \"algo_\" concatenated with algorithm name. For instance, if algorithm name is \"Greedy\", column header should be \"algo_greedy\". If name consists of more than one word, each word should be separated by \"\\_\" (spaces are not allowed). You can add the performance of more than one algorithm in the same csv. This column is required either in \"Custom Problem\" or if you want to add more algorithms in the analysis of a library problem.)_\n",
    "\n",
    "\n",
    "__5)__ Com o meta conjunto de dados pronto, executar a análise do Matilda. Dá também para fazer uma pré-seleção dos meta-atributos antes, mas aí podemos discutir depois como fazer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neighbors import NearestNeighbors, KernelDensity\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "pandas_bokeh.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.realpath(\"../data/\")\n",
    "\n",
    "metadata_path = os.path.join(data_path, \"metadata.csv\")\n",
    "overlap_path = os.path.join(data_path, \"overlap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv(metadata_path, index_col='instances')\n",
    "df_overlap = pd.read_csv(overlap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=sns.scatterplot(data=df_overlap, x='V1', y='V2', hue='class', legend=\"full\", palette='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_overlap[['V1', 'V2']]\n",
    "y = df_overlap['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pyhard.Measures(df_overlap, labels_col='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.build_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_true: np.ndarray, y_pred: np.ndarray, eps=1e-15):\n",
    "    enc = OneHotEncoder()\n",
    "    y_true = enc.fit_transform(y_true.reshape(-1, 1)).toarray()\n",
    "    \n",
    "    y_pred = np.clip(y_pred, eps, 1-eps)\n",
    "    return -np.sum(y_true * np.log(y_pred), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(y.values.reshape(-1, 1))\n",
    "v=enc.transform(y.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[1,2,3]])\n",
    "a.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logloss(y.values, clf.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Disagreeing Neighbors (kDN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto', metric='euclidean').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kDN = []\n",
    "for i in range(0, len(df_overlap)):\n",
    "    v = df_overlap.loc[indices[i]]['class'].values\n",
    "    kDN.append(np.sum(v[1:] != v[0]) / k)\n",
    "df_overlap['kDN'] = kDN\n",
    "df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df_metadata['feature_KDN'].values, y=df_overlap['kDN'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap.loc[indices[4]]['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunct Size (DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini', min_samples_split=2) # min_samples_leaf=1\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import graphviz \n",
    "\n",
    "# dot_data = tree.export_graphviz(clf, \n",
    "#                                 out_file=None, \n",
    "#                                 feature_names=['V1', 'V2'],\n",
    "#                                 class_names=['1', '2'],\n",
    "#                                 filled=True, rounded=True,  \n",
    "#                                 special_characters=True) \n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap['leaf_id'] = clf.apply(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_overlap.groupby('leaf_id').count().iloc[:,0].to_frame('count').subtract(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = df_overlap.join(df, on='leaf_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap['DS'] = df_overlap['count'].divide(df_overlap['count'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunct Class Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'ccp_alpha': np.linspace(0.001, 0.1, num=100)}\n",
    "dtc = tree.DecisionTreeClassifier(criterion='gini')\n",
    "clf_prune = GridSearchCV(dtc, parameters)\n",
    "clf_prune = clf_prune.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_prune.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier(criterion='gini', ccp_alpha=clf_prune.best_params_['ccp_alpha'])\n",
    "dtc = dtc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap['leaf_id'] = dtc.apply(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df3 = df_overlap.rename(columns={'class':'y'})\n",
    "dcp = []\n",
    "for index, row in df3.iterrows():\n",
    "    df_leaf = df3[df3['leaf_id'] == row['leaf_id']]\n",
    "    dcp.append(len(df_leaf[df_leaf['y'] == row['y']]) / len(df_leaf))\n",
    "    \n",
    "df3['DCP'] = dcp\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df_metadata['feature_TD'].values, y=TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = X.apply(lambda x: dtc.decision_path([x]).sum()-1, axis=1, raw=True).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Likeliood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['V1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(X['V2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB(priors=[0.5, 0.5])\n",
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = nb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = y.values\n",
    "CL=[prob[i, lab[i]-1] for i in range(0,len(lab))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLD = [prob[i, lab[i]-1]-np.delete(prob[i,:], lab[i]-1).max() for i in range(0,len(lab))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(np.array([1,2,3,4,5]), 4).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=df_metadata['feature_CLD'].values, y=CLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minority Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MVc = df_overlap.groupby('class').count().iloc[:,0]\n",
    "MVc=MVc.divide(MVc.max())\n",
    "\n",
    "1-y.apply(lambda c: MVc[c]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = gower.gower_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import minimum_spanning_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tcsr = minimum_spanning_tree(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst = Tcsr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst = np.where(mst>0, mst, np.inf)\n",
    "c = y.values\n",
    "N1 = np.zeros(c.shape)\n",
    "for i in range(len(c)):\n",
    "    idx = np.argwhere(np.minimum(mst[i,:], mst[:,i]) < np.inf)\n",
    "    assert len(idx) > 0\n",
    "    N1[i] = np.sum(c[idx[:,0]] != c[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1[N1>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(X)\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='euclidean').fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(dist_matrix, axis=1)\n",
    "distances = np.sort(dist_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = np.zeros(y.values.shape)\n",
    "for i, value in y.items():\n",
    "    nn = y.loc[indices[i,:]]\n",
    "    intra = nn.eq(value) # .idxmax()\n",
    "    extra = nn.ne(value) # .idxmax()\n",
    "    assert np.all(np.diff(distances[i, intra]) >= 0)\n",
    "    assert np.all(np.diff(distances[i, extra]) >= 0)\n",
    "    N2[i] = distances[i, intra][1]/distances[i, extra][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
