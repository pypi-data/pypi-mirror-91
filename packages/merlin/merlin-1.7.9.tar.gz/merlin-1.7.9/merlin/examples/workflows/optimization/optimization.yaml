description:
  name: optimization
  description: Design Optimization Template

##TODO
# DONE Step to delete run_sim files
# DONE: Removing the make-samples.py script
# Ability to change the test function
  # Need to make sure visualizer step doesn't get affected
# Ability to change the learner
# Ability to change optimizer

env:
  variables:
    EMAIL_ADDRESS: "enter your email address here, or override this with --vars"
    N_DIMS: 2
    METHOD: 'trust-constr'

    ITER: 1
    MAX_ITER: 3

    SCRIPTS: $(SPECROOT)/scripts

    DIM_1_MIN: -2.0
    DIM_1_MAX: 2.0
    DIM_2_MIN: -1.0
    DIM_2_MAX: 3.0
    DIM_1_UNCERT: 0.1
    DIM_2_UNCERT: 0.1

    BOUNDS_X: "[[$(DIM_1_MIN),$(DIM_1_MAX)],[$(DIM_2_MIN),$(DIM_2_MAX)]]"
    UNCERTS_X: "[$(DIM_1_UNCERT),$(DIM_2_UNCERT)]"

    # pick_new_inputs step
    SEARCH_SCALE: 0.30
    N_SAMPLES: 5 # Number of new samples per iteration around the predicted new point
    N_EXPLOIT: 5 # Number of new samples per iteration around the current best
    N_SAMPLES_LINE: 5 # Number between predicted best and current best
    N_SAMPLES_START: 20 # Number to initialize


study:
    - name: run_simulation
      description: Run the desired simulation
      run:
        cmd: |-
          python3 $(SCRIPTS)/test_functions.py -ID "$(ITER)/$(MERLIN_SAMPLE_ID)" -inputs $(DIM_1) $(DIM_2)

        cores per task: 1
        nodes: 1
        procs: 1
        task_queue: simulation

    - name: collector
      description: Collect the results into a single file and make an npz of some features
      run:
        cmd: |-
          python3 $(SCRIPTS)/collector.py -sim_dirs "$(run_simulation.workspace)/$(MERLIN_GLOB_PATH)"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [run_simulation_*]
        task_queue: simulation_postprocess

    - name: clean_up_simulation
      description: Cleans up the merlin sample paths of the run_simulation step
      run:
        cmd: |-
          rm -rf $(run_simulation.workspace)/$(MERLIN_SAMPLE_PATH)

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [collector]
        task_queue: simulation_postprocess

    - name: learner
      description: Train an ML model on the simulation
      run:
        cmd: |-
          temp=1
          if [ $(ITER) -ge "$temp" ] ; then
              echo "Copying the npz file from previous iteration"
              cp ../../../learner/all_iter_results.npz .
          fi

          python3 $(SCRIPTS)/learner.py -collector_dir "$(collector.workspace)"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [clean_up_simulation]
        task_queue: learner

    - name: optimizer
      description: Optimizer
      run:
        cmd: |-
          python3 $(SCRIPTS)/optimizer.py -learner_dir "$(learner.workspace)" -bounds "$(BOUNDS_X)" -input_uncerts "$(UNCERTS_X)" -method "$(METHOD)"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [collector, learner]
        task_queue: learner

    - name: pick_new_inputs
      description: Picking new simulations to run in the next iteration
      run:
        cmd: |-
          spellbook make-samples -dims $(N_DIMS) -x0 $(optimizer.workspace)/optimum.npy -x1 $(optimizer.workspace)/old_best.npy -n_line $(N_SAMPLES_LINE) -scale_factor $(SEARCH_SCALE) -scale "$(BOUNDS_X)" -n $(N_SAMPLES) -sample_type lhd -outfile new_explore_samples.npy --hard-bounds
          spellbook make-samples -dims $(N_DIMS) -x0 $(optimizer.workspace)/optimum.npy -scale_factor 0.05 -scale "$(BOUNDS_X)" -sample_type star -outfile new_explore_star_samples.npy --hard-bounds
          # Add points near current best too
          spellbook make-samples -dims $(N_DIMS) -x0 $(optimizer.workspace)/old_best.npy -scale_factor $(SEARCH_SCALE) -scale "$(BOUNDS_X)" -n $(N_EXPLOIT) -sample_type lhd -outfile new_exploit_samples.npy --hard-bounds

          # combine them
          python3 -c "import numpy as np; np.save('new_samples.npy',np.vstack((np.load('new_explore_samples.npy'),np.load('new_exploit_samples.npy'),np.load('new_explore_star_samples.npy'))))"

        cores per task: 1
        nodes: 1
        procs: 1
        depends: [optimizer]
        task_queue: learner

    - name: visualizer
      description: Either launches new simulations or iterated with inputs from previous step
      run:
        cmd: |-
          # Add an if statment to make sure it is rosenbrock function and 2D
          python3 $(SCRIPTS)/visualizer.py -study_dir $(MERLIN_WORKSPACE)
        cores per task: 1
        nodes: 1
        procs: 1
        depends: [pick_new_inputs]
        task_queue: learner

    - name: iterate
      description: Either launches new simulations or iterated with inputs from previous step
      run:
        cmd: |-
          cp $(optimizer.workspace)/optimization_results.json optimization_results_iter_$(ITER).json
          cp $(visualizer.workspace)/results.png results_iter_$(ITER).png
          echo "Done iteration $(ITER) in $(MERLIN_WORKSPACE)" | mail -s "Status $(MERLIN_WORKSPACE)" -a optimization_results_iter_$(ITER).json -a results_iter_$(ITER).png $(EMAIL_ADDRESS)

          if [ $(ITER) -ge $(MAX_ITER) ] ; then
              echo "done"
          else
              next_iter=$(ITER)
              ((next_iter=next_iter+1))
              echo "Starting iteration " $next_iter
              merlin run --local $(MERLIN_INFO)/*partial.yaml --samplesfile $(pick_new_inputs.workspace)/new_samples.npy --vars ITER=$next_iter
          fi
        cores per task: 1
        nodes: 1
        procs: 1
        depends: [visualizer]
        task_queue: learner

merlin:
  resources:
    overlap: true
    task_server: celery
    workers:
      all_workers:
        args: -O fair --prefetch-multiplier 1 -E -l info --concurrency 20
        steps: [all]
  samples:
    column_labels:
    - DIM_1
    - DIM_2
    file: $(MERLIN_INFO)/samples.npy
    generate:
      cmd: |-
          spellbook make-samples -dims $(N_DIMS) -n $(N_SAMPLES_START) -sample_type lhs -outfile=$(MERLIN_INFO)/samples.npy -scale "$(BOUNDS_X)"
