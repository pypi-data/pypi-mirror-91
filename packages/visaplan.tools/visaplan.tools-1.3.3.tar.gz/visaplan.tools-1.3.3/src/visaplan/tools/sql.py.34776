# -*- coding: utf-8 -*- äöü
"""
visaplan.tools.sql: helpers for SQL processing

Autor: Tobias Herp
"""
from __future__ import absolute_import

from six import string_types as six_string_types
from six.moves import map, zip

from visaplan.tools.minifuncs import check_kwargs

__all__ = [# SQL code generation functions:
           'insert',
           'update',
           'delete',
           'select',
           # (helpers) 
           'replace_names',
           "make_where_mask",
           'SafeNames',  # (a class)
           # ... so far all use the pg_placeholder function:
           'pg_placeholder',
           # ... which is the default placeholder argument for:
           'make_SqlGenerators',
           # You may create SQL generators following the SQLAlchemy style
           # by calling make_SqlGenerators( 
           'sqlalchemy_placeholder',
           # ) ... wich will return a tuple of functions (and a class)
            
           # The following functions are currenly placeholder-agnostic
           # and can be generated as ordinary module functions: 
           # SQL names:
           'check_name',
           "check_alias",
           # SQL generation:
           "make_transaction_cmd",
           "make_returning_clause",
           # Formatting:
           "normalize_sql_snippet",
           # helpers:
           'subdict_ne',  # ... generated by:
           'make_dict_extractor',
           "extract_dict",  # deprecated; please consider using subdict_ne
           'generate_dicts',
           "is_sequence",
           ]

from string import letters, uppercase, whitespace, digits
NAMECHARS = frozenset(letters+'._')
ALLNAMECHARS = frozenset(letters+digits+'._')
SNIPPETCHARS = frozenset(uppercase + whitespace)


def check_name(sqlname, for_select=False):
    """
    Prüfe, ob der übergebene Name einer SQL-Tabelle (oder sonstigen
    benannten Ressource) syntaktisch valide und ohne Quoting
    verwendbar ist.  Gib den Namen im Erfolgsfall unverändert zurück;
    wirf ansonsten einen ValueError.

    >>> check_name('tan.tan')
    'tan.tan'

    Ziffern, die kein Segment einleiten, sind erlaubt:

    >>> check_name('witrabau.p2_witrabau_partners_view')
    'witrabau.p2_witrabau_partners_view'

    Am Anfang eines Segments sind sie aber verboten:

    >>> check_name('witrabau.2_witrabau_partners_view')
    Traceback (most recent call last):
      ...
    ValueError: Error in 'witrabau.2_witrabau_partners_view': '2' must not start a segment

    Doppelte Punkte:
    >>> check_name('tan..tan')
    Traceback (most recent call last):
      ...
    ValueError: Empty segment in 'tan..tan'

    Leere Namen:
    >>> check_name('')
    Traceback (most recent call last):
      ...
    ValueError: Empty segment in ''
    """
    if not isinstance(sqlname, six_string_types):
        raise TypeError('%r is not a string' % (sqlname,))

    invalid = set(sqlname).difference(ALLNAMECHARS)
    if invalid:
        raise ValueError('Invalid chars in %r: %s'
                         % (sqlname, tuple(invalid),))
    for s in sqlname.split('.'):
        if not s:
            raise ValueError('Empty segment in %r' % sqlname)
        if s[0] not in NAMECHARS:
            raise ValueError('Error in %r: %r must not start a segment'
                             % (sqlname, s[0]))
    return sqlname


def check_alias(sqlname):
    """
    Wie check_name, aber mit Unterstützung für AS-Angaben
    (sinnvoll z.B. für returning-Angaben):
    >>> check_alias('id AS user_and_course_id')
    'id AS user_and_course_id'

    Achtung, gleichbedeutend:
    >>> check_alias('id user_and_course_id')
    'id user_and_course_id'

    Offensichtliche Fehler werden erkannt:
    >>> check_alias('id user_and_course_id zwei')
    Traceback (most recent call last):
      ...
    ValueError: Part 'id user_and_course_id zwei': AS expected, found: 'user_and_course_id'
    >>> check_alias('id AS user_and_course_id zwei')
    Traceback (most recent call last):
      ...
    ValueError: Part too long ('id AS user_and_course_id zwei')
    >>> check_alias('id as')
    Traceback (most recent call last):
      ...
    ValueError: Misplaced AS ('id as')
    >>> check_alias('as user_and_course_id ')
    Traceback (most recent call last):
      ...
    ValueError: Misplaced AS ('as user_and_course_id ')
    >>> check_alias('   ')
    Traceback (most recent call last):
      ...
    ValueError: Empty name or alias ('   ')
    """
    if sqlname == '*':
        return sqlname
    words = sqlname.split()
    if not words:
        raise ValueError('Empty name or alias (%(sqlname)r)' % locals())
    if words[3:]:
        raise ValueError('Part too long (%(sqlname)r)' % locals())
    if not words[2:]:
        for word in words:
            if word.upper() == 'AS':
                raise ValueError('Misplaced AS (%(sqlname)r)' % locals())
            check_name(word)
    else:
        if words[1].lower() != 'as':
            raise ValueError('Part %r: AS expected, found: %r'
                             % (sqlname, words[1]))
        for word in words[0::2]: # 0, 2, 4 ... aber: siehe oben
            if word.upper() == 'AS':
                raise ValueError('Misplaced AS (%(sqlname)r)' % locals())
            check_name(word)
    return sqlname


def generate_dicts(sqlres, names):
    """
    Zur Verwendung mit INSERT ... RETURNING:
    Erzeuge aus dem Rückgabewert von db.query eine Sequenz von Dictionarys.

    sqlres -- ein 2-Tupel; der zweite Wert ist eine Liste von Tupeln
    names -- eine Sequenz von Namen

    >>> res = ([{'scale': None, 'name': 'id', 'precision': None, 'width': None, 'null': None, 'type': 'n'}], [(3,)])
    >>> list(generate_dicts(res, names=('id',)))
    [{'id': 3}]
    >>> list(generate_dicts(res, names='id'))
    [{'id': 3}]
    >>> list(generate_dicts(res, names='*'))
    [{'id': 3}]
    """
    if names == '*':
        names = [topic['name'] for topic in sqlres[0]]
    elif not is_sequence(names):
        names = [names]
    raw = sqlres[1]
    for row in raw:  # no dict(list(zip())) necessary, right?
        yield dict(zip(names, row))


def normalize_sql_snippet(snippet):
    """
    Normalisiere einen SQL-Schnipsel und gib ihn zurück.
    Im Ergebnis sind nur Großbuchstaben und ggf. Leerzeichen enthalten;
    evtl. wird ein ValueError geworfen.

    Achtung: keine Namen (Identifier), keine Werte!

    >>> normalize_sql_snippet('  read  only  ')
    'READ ONLY'

    >>> normalize_sql_snippet('select * from my.table;')
    Traceback (most recent call last):
      ...
    ValueError: Invalid chars in 'select * from my.table;': ('*', '.', ';')
    """
    res = ' '.join(snippet.upper().split())
    invalid = set(res).difference(SNIPPETCHARS)
    if invalid:
        raise ValueError('Invalid chars in %r: %s'
                         % (snippet, tuple(sorted(invalid)),))
    return res

ISOLATION_LEVELS = set(['SERIALIZABLE',
                        'REPEATABLE READ',
                        'READ COMMITTED',
                        'READ UNCOMMITTED', # in PostgreSQL wie read committed
                        ])
TRANSACTION_MODES = set(['READ WRITE',
                         'READ ONLY',
                         ])
for item in ISOLATION_LEVELS:
    TRANSACTION_MODES.add(item)
    TRANSACTION_MODES.add('ISOLATION LEVEL '+item)


# http://www.postgresql.org/docs/9.1/static/sql-start-transaction.html
# http://www.postgresql.org/docs/9.1/static/sql-set-transaction.html
def make_transaction_cmd(action, *args):
    """
    Nimm einige Spezifikationen für Transaktionen entgegen
    und erzeuge daraus das entsprechende SQL-Statement.

    >>> make_transaction_cmd('BEGIN')
    'BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED;'
    >>> make_transaction_cmd('SET', 'read only')
    'SET TRANSACTION READ ONLY;'
    """
    assert action in ('BEGIN', 'SET')
    isolation_level = None
    other_specs = []
    for a in args:
        AA = normalize_sql_snippet(a)
        if AA in ISOLATION_LEVELS:
            isolation_level = 'ISOLATION LEVEL ' + AA
        elif AA in TRANSACTION_MODES:
            if AA.startswith('ISOLATION LEVEL '):
                isolation_level = AA
            else:
                other_specs.append(AA)
        else:
            raise ValueError('Unbekannter Transaktionsmodus: %r' % (AA,))
    if isolation_level is None and action == 'BEGIN':
        isolation_level = 'ISOLATION LEVEL READ COMMITTED'
    if isolation_level is not None:
        other_specs.insert(0, isolation_level)
    return '%s TRANSACTION %s;' % (action, ', '.join(other_specs))


WHERE = intern('WHERE')

def is_sequence(arg):
    """
    Handelt es sich im Sinne von SQL um eine Sequenz (abzugleichen mit
    ... = ANY (...) anstelle von ... = ...)?

    >>> is_sequence('test')
    False
    >>> is_sequence(['a', 'b'])
    True
    >>> is_sequence(42)
    False

    Auch Generatoren werden erkannt:
    >>> is_sequence(xrange(1, 3))
    True
    """
    if hasattr(arg, 'strip'):
        return False
    return (hasattr(arg, "__getitem__") or
            hasattr(arg, "__iter__")
            )


def make_returning_clause(fields):
    """
    Gib eine RETURNING-Klausel zurück (PostgreSQL-Erweiterung gegenüber
    dem SQL-Standard, ab Version 9.1):

    >>> make_returning_clause('*')
    'RETURNING *'
    >>> make_returning_clause('id')
    'RETURNING id'
    >>> make_returning_clause(['tan', 'status'])
    'RETURNING tan, status'

    Solche returning-Ausdrücke werden vom Datenbanktreiber derzeit leider nicht
    korrekt interpretiert - es kommt ein Feldname "is AS some_better_name"
    dabei heraus.  Deshalb prüfen wir hier vorerst weiterhin mit check_name,
    nicht mit check_alias:
    >>> make_returning_clause('id AS some_better_name')
    Traceback (most recent call last):
        ...
    ValueError: Invalid chars in 'id AS some_better_name': (' ',)
    """
    if fields == '*':
        return 'RETURNING *'
    if not is_sequence(fields):
        liz = [fields]
    else:
        liz = fields
    return 'RETURNING ' + ', '.join(map(check_name, liz))


def extract_dict(fields, source, pop=1, noempty=1):
    """
    Extrahiere die angegebenen Felder aus dem Quell-Dictionary,
    um sie beispielsweise in eine andere Tabelle zu schreiben.
    Dabei werden die gefundenen Schlüssel normalerweise aus der Quelle
    gelöscht:

    >>> source={'tan': 123, 'status': 'new', 'owner_id': 'Willy'}
    >>> extract_dict(['status'], source)
    {'status': 'new'}
    >>> source
    {'tan': 123, 'owner_id': 'Willy'}

    Wird pop=0 übergeben, bleibt die Quelle unverändert erhalten:

    >>> extract_dict(['owner_id'], source, pop=0)
    {'owner_id': 'Willy'}
    >>> source
    {'tan': 123, 'owner_id': 'Willy'}

    In der Quelle nicht vorhandene Schlüssel werden übergangen,
    erzeugen also keinen Fehler:

    >>> extract_dict(['owner_id', 'group_id'], source, pop=0)
    {'owner_id': 'Willy'}
    >>> source
    {'tan': 123, 'owner_id': 'Willy'}

    Mit noempty=True (Standardwert) werden "leere" Werte (wie nach dem
    Absenden von Web-Formularen sehr häufig) weggelassen:

    >>> form={'group_id': 'group_abc', 'status': '', 'zahl': '0'}
    >>> all=['group_id', 'status', 'zahl']
    >>> extract_dict(all, form, pop=1, noempty=1)
    {'group_id': 'group_abc', 'zahl': '0'}

    Diese leeren Werte sind im Falle von pop=True dann trotzdem in der
    Quelle gelöscht:
    >>> form
    {}

    Siehe auch die allgemeinere Funktion visaplan.tools.dicts.subdict
    und ihren Wrapper subdict_forquery.
    """
    get = pop and source.pop or source.get
    res = {}
    if noempty:
        for field in fields:
            if field in source:
                val = get(field)
                if val not in (None, ''):
                    res[field] = val
    else:
        for field in fields:
            if field in source:
                res[field] = get(field)
    return res


def make_dict_extractor(**kwargs):
    """
    Create a subdict extractor for SQL use
    which will ...

    - automatically drop fields with "empty" values
      (which are often useless for filtering),
      unless `noempty` is `False`
    - gracefully *ignore* any missing fields
    - never use any default values

    In some of these respects the generated function differs from
    .dicts.subdict.

    >>> def tst(func, *args, **kwargs):
    ...     return sorted(func(*args, **kwargs).items())
    >>> fne = make_dict_extractor()
    >>> tst(fne, {'number': 0, 'str': '', 'anything': None})
    [('number', 0)]

    Now we'll create an extrator which won't check for "empty" values:
    >>> fie = make_dict_extractor(noempty=False)

    >>> tst(fie, {'number': 0, 'str': '', 'anything': None})
    [('anything', None), ('number', 0), ('str', '')]

    If we are not interested in *all* keys of the dictionary
    we can specify the fields to use; if we use a string, it will be split:

    >>> tst(fie, {'number': 2, 'str': '', 'anything': None}, 'number missing')
    [('number', 2)]

    We publish a standard extractor function `subdict_ne`
    which regards the default `empty_values`:

    >>> subdict_ne({'number': 0, 'str': '', 'anything': None})
    {'number': 0}

    Other than `.dicts.subdict`, this function won't ever complain
    about missing keys nor inject default values:

    >>> subdict_ne({'number': 42, 'anything': None}, ['number', 'missing'])
    {'number': 42}

    See as well `.dicts.subdict_forquery` which sports *all* options of the `subdict` function
    (which it calls internally) but currently only filters out None values.

    TODO: add a `strict` option here as well; but first we'll need to consider
          whether it should be True or False by default.
    """
    do_pop = kwargs.pop('pop', 1) or 0
    if 'noempty' in kwargs:
        noempty = kwargs.pop('noempty')
        empty_values = kwargs.pop('empty_values', set([None, '']))
    else:
        empty_values = kwargs.pop('empty_values', set([None, '']))
        noempty = bool(empty_values)

    def sql_subdict(source, fields=None, pop=do_pop):
        get = pop and source.pop or source.get
        res = {}
        if fields is None:
            fields = source.keys()
        elif isinstance(fields, six_string_types):
            fields = fields.split()
        for field in fields:
            if field in source:
                res[field] = get(field)
        return res

    def sql_subdict_noempty(source, fields=None, pop=do_pop):
        get = pop and source.pop or source.get
        res = {}
        if fields is None:
            fields = source.keys()
        elif isinstance(fields, six_string_types):
            fields = fields.split()
        for field in fields:
            if field in source:
                val = get(field)
                if val not in empty_values:
                    res[field] = val
        return res

    return (sql_subdict_noempty if noempty
            else sql_subdict)
subdict_ne = make_dict_extractor()

# ---------------------------------- [ SQL-Statements generieren ... [
def pg_placeholder(key):
    """
    Turn a field name in a psycopg2-style placeholder

    >>> pg_placeholder('name')
    '%(name)s'

    This function is usually not directly used; it is the default placeholder
    argument for the make_SqlGenerators factory function.
    """
    if not key:
        raise ValueError('Empty field name %(key)r!' % locals())
    return key.join(('%(', ')s'))


def sqlalchemy_placeholder(key):
    """
    Turn a field name in an SQLAlchemy-style placeholder

    >>> sqlalchemy_placeholder('name')
    ':name'

    This function is usually not directly used; it can be specified as
    placeholder argument to the make_SqlGenerators factory function.

    We don't expect this to be necessary very often, since you'll want to use
    SQLAlchemy's facilities instead.
    """
    if not key:
        raise ValueError('Empty field name %(key)r!' % locals())
    return ':'+key


def make_where_mask_maker(placeholder):
    def make_where_mask(dic, fields=None, keyword=WHERE):
        """
        Komfort-Funktion; wenn die Query-Daten schon als dict vorliegen,
        braucht man sich die WHERE-Bedingung nicht aus den Fingern zu saugen.
        Ohne Daten ist das Ergebnis ein Leerstring (also auch ohne 'WHERE').

        dic -- die Query-Daten. Es werden nur die Schlüssel verwendet; die Werte
               werden beim Absenden der Query vom SQL-Adapter eingesetzt.

        fields -- wenn angegeben, werden die in <fields> aufgeführten Schlüssel
                  bevorzugt behandelt; ansonsten bestimmt sich die Reihenfolge
                  nach ASCII-Sortierung.

        >>> make_where_mask({})
        ''
        >>> make_where_mask({'answer': 42})
        'WHERE answer = %(answer)s'
        >>> query_data={'zwei': 2, 'eins': 1}
        >>> make_where_mask(query_data)
        'WHERE eins = %(eins)s AND zwei = %(zwei)s'
        >>> len(query_data)
        2
        >>> make_where_mask(query_data, ['zwei', 'eins'])
        'WHERE zwei = %(zwei)s AND eins = %(eins)s'

        'drei' ist in der fields-Liste nicht erwähnt und kommt daher zum Schluß:

        >>> query_data['drei'] = 3
        >>> make_where_mask(query_data, ['zwei', 'eins'])
        'WHERE zwei = %(zwei)s AND eins = %(eins)s AND drei = %(drei)s'

        Unterstützung von Sequenzen:

        >>> make_where_mask({'status': ['new', 'reserved']})
        'WHERE status = ANY(%(status)s)'

        Bei Verwendung von Gruppierung und Aggregatfunktionen:

        >>> make_where_mask({'status': ['new', 'reserved']}, keyword='HAVING')
        'HAVING status = ANY(%(status)s)'

        >>> make_where_mask_maker(sqlalchemy_placeholder)({'status': ['new', 'reserved']}, keyword='HAVING')
        'HAVING status = ANY(:status)'
        """
        assert keyword in (WHERE, 'HAVING')
        keys = sorted(dic.keys())
        if fields:
            po = len(fields)
            tmp = []
            for key in keys:
                try:
                    idx = fields.index(key)
                    tmp.append((idx, key))
                except ValueError:
                    tmp.append((po, key))
                    po += 1
            tmp.sort()
            keys = [tup[1] for tup in tmp]
        if keys:
            res = []
            for key in keys:
                if is_sequence(dic[key]):
                    res.append(''.join((key, ' = ANY(', 
                                        placeholder(key),
                                        ')')))
                else:
                    res.append(''.join((key, ' = ',
                                        placeholder(key))))
            return ' '.join((keyword, ' AND '.join(res)))
        return ''

    return make_where_mask


def make_SqlGenerators(placeholder):
    r"""
    Create and return a class which provides static methods
    to generate SQL code.

    By default, this produces SQL statements using '%(fieldname)s'
    placeholders, like needed e.g. for psycopg2 (see the doctests for the
    select, insert ... static methods below;

    however, you can specify your own placeholder factory function,
    e.g. sqlalchemy_placeholder, to generate SQL like expected by SQLAlchemy.

    >>> INSERT, UPDATE, DELETE, SELECT = \
    ...     make_SqlGenerators(sqlalchemy_placeholder)[:4]
    >>> INSERT('die_tabelle', {'name': 'Zaphod', 'heads': 2})[0]
    'INSERT INTO die_tabelle (heads, name) VALUES (:heads, :name);'
    >>> INSERT('die_tabelle', {'name': 'Zaphod', 'heads': 2},
    ...        returning='id')[0]
    'INSERT INTO die_tabelle (heads, name) VALUES (%(heads)s, %(name)s) RETURNING id;'
    """
    class SafeNames(dict):
        """
        Für die Generierung von SQL-Anweisungen:
        Ein Dictionary, das die ihm bekannten Werte ersetzt
        und für die anderen den Platzhalter repliziert.

        >>> smartie = SafeNames(foo='bar')
        >>> '%(foo)s %(baz)s' % smartie
        'bar %(baz)s'
        """
        def __getitem__(self, key):
            """
            >>> sd = SafeNames()
            >>> sd.__getitem__('missing')
            '%(missing)s'
            """
            try:
                return dict.__getitem__(self, key)
            except KeyError:
                check_name(key)
                return placeholder(key)

    make_where_mask = make_where_mask_maker(placeholder)

    def replace_names(sql, **kwargs):
        """
        Zur Vorverarbeitung: Sicheres Ersetzen von Tabellen- und
        sonstigen Namen, bevor der Datenbankadapter für das Quoting der
        Werte sorgt.

        Die Tabellen...namen werden *nicht* gequotet, weil das das Ende
        der Groß-/Kleinschreibungstoleranz bedeuten würde; stattdessen
        wird sichergestellt, daß keine gefährlichen Zeichen enthalten
        sind.

        sql - das SQL-Statement
        kwargs -- Platzhalter und Werte für die Namen von Tabellen o.ä.
                  (werden mit check_name überprüft)

        >>> replace_names('SELECT * FROM %(table)s WHERE val=%(val)s;', table='fozzie')
        'SELECT * FROM fozzie WHERE val=%(val)s;'
        """
        for v in kwargs.values():
            check_name(v)
        dic = SafeNames(kwargs)
        return sql % dic

    def insert(table, dict_of_values,  # ------------- [ insert ... [
               **kwargs):
        """
        Return a simple "INSERT INTO ..." SQL statement with placeholders
        and a values dict.

        Mandatory arguments:

          table -- name of the table (may contain the schema)
          dict_of_values -- a Python dict containing the values

        Keyword-only options:

          returning -- like supported by PostgreSQL 9.1+
          strict -- if False, unknown keyword arguments will be silently ignored;
                    if True (default), a TypeError will be raised.

        >>> insert('die_tabelle', {'name': 'Zaphod', 'heads': 2})[0]
        'INSERT INTO die_tabelle (heads, name) VALUES (%(heads)s, %(name)s);'
        >>> insert('die_tabelle', {'name': 'Zaphod', 'heads': 2},
        ...        returning='id')[0]
        'INSERT INTO die_tabelle (heads, name) VALUES (%(heads)s, %(name)s) RETURNING id;'

        (As for the INSERT statement, the 2nd returned value is not very interesting -
        it is the `dict_of_values` which was given as an argument.)
        """
        keys = list(dict_of_values.keys())
        rows = ', '.join(keys)
        values = ', '.join([key.join(('%(', ')s'))
                            for key in keys
                            ])
        query_l = [replace_names('INSERT INTO %(table)s',
                                 table=table),
                   '(%s)' % rows,
                   'VALUES (%s)' % values,
                   ]
        check_kwargs(kwargs,
                     allowed=set(['returning', 'strict']))
        returning = kwargs.get('returning')
        if returning:
            query_l.append(make_returning_clause(returning))
        statements = [' '.join(query_l)]
        statements.append('')
        query = ';'.join(statements)
        return query, dict_of_values
        # -------------------------------------------- ] ... insert ]

    def update(table, dict_of_values,  # ------------- [ update ... [
               query_data=None,
               **kwargs):
        """
        Return a simple "UPDATE ..." SQL statement with placeholders
        and a values dict.

        Arguments:

          table -- name of the table (may contain the schema)
          dict_of_values -- a Python dict containing the new values
          query_data -- another dict with a disjunct set of keys
                        to restrict the rows changed.

        Keyword-only options:

          where -- a "WHERE ..." string (which may contain placeholders);
                   currently necessary if some fields are both changed
                   and used in the filtering `query_data`
          returning -- like supported by PostgreSQL 9.1+
          strict -- if False, unknown keyword arguments will be silently ignored;
                    if True (default), a TypeError will be raised.
          fork -- Rarely specified: Whether to create a copy of the `query_data`
                  before merging in the `dict_of_values`.
                  Defaults to True.

          fork -- wenn <query_data> nach dem Methodenaufruf noch verwendet
                  werden soll, muß intern eine Kopie angelegt werden

        >>> tup = update('the_table', {'status': 'done'},
        ...              {'id': [47, 11]})
        >>> tup[0]
        'UPDATE the_table SET status=%(status)s WHERE id = ANY(%(id)s);'
        >>> tup[1]
        {'status': 'done', 'id': [47, 11]}

        Die Funktion akzeptiert zwei Dictionary-Optionen, die oft zusammen verwendet werden;
        was passiert mit etwaigen Variablen?

        >>> values = {'status': 'success'}
        >>> query_data = {'id': [1, 2, 5]}
        >>> tup2 = update('the.table', values, query_data)
        >>> tup2[0]
        'UPDATE the.table SET status=%(status)s WHERE id = ANY(%(id)s);'
        >>> tup2[1]
        {'status': 'success', 'id': [1, 2, 5]}

        Beide Eingabe-Dictionarys sind unverändert:

        >>> values
        {'status': 'success'}
        >>> query_data
        {'id': [1, 2, 5]}

        Was ist, wenn ein Feldname sowohl im Filter als auch in den zugewiesenen Werten auftaucht?

        >>> update('the_table', {'status': 'done'}, {'status': None})
        Traceback (most recent call last):
        ...
        ValueError: key 'status' is both in query data (None) and update data ('done')!

        In solchen Fällen kann man sich helfen, indem man selbst einen where-String angibt:

        >>> tup3 = update('the_table', {'status': 'done'},
        ...               where='WHERE status is NULL')
        >>> tup3[0]
        'UPDATE the_table SET status=%(status)s WHERE status is NULL;'
        >>> tup3[1]
        {'status': 'done'}

        >>> tup4 = update('the_table', {'status': 'done'}, {'status_old': 'in_progress'},
        ...               where='WHERE status = %(status_old)s')
        >>> tup4[0]
        'UPDATE the_table SET status=%(status)s WHERE status = %(status_old)s;'
        >>> tup4[1]
        {'status': 'done', 'status_old': 'in_progress'}

        """
        keys = list(dict_of_values.keys())
        qset = ', '.join([''.join((key, '=%(', key, ')s'))
                          for key in keys
                          ])
        query_l = [replace_names('UPDATE %(table)s SET',
                                 table=table),
                   qset,
                   ]
        if query_data is not None:
            if not isinstance(query_data, dict):
                raise ValueError('query_data must be a dict; found %(query_data)r'
                                 % locals())
            query_keys = set(query_data.keys())
            value_keys = set(keys)
            keys_of_both = value_keys.intersection(query_keys)
            if keys_of_both:
                # Löschen aus Set während Iteration nicht erlaubt;
                # also iteration über "Kopie":
                for key in sorted(keys_of_both):
                    u_val = dict_of_values[key]
                    q_val = query_data[key]
                    if u_val == q_val:
                        del dict_of_values[key]
                        keys_of_both.remove(key)
                    else:
                        raise ValueError ('key %(key)r is both'
                                     ' in query data (%(q_val)r)'
                                     ' and update data (%(u_val)r)!'
                                     % locals())
            if not dict_of_values:
                raise ValueError('Empty update data!')
            if keys_of_both:
                raise ValueError('intersection of value keys and '
                                 'query keys (%(keys_of_both)s: '
                                 'currently unsupported!'
                                 % locals())
            fork = kwargs.get('fork', True)
            if fork:
                query_data = dict(query_data)  # wg. Wiederverwendung!
        else:
            query_data = {}
            fork = kwargs.get('fork', False)
        check_kwargs(kwargs,
                     allowed=set(['returning', 'where', 'fork',
                                  'strict']))
        where = kwargs.get('where')
        if where and not isinstance(where, six_string_types):
            raise ValueError('where must be a string; found %(where)r'
                             % locals())
        if query_data and not where:
            where = make_where_mask(query_data)

        if where:
            query_l.append(where)

        returning = kwargs.get('returning')
        if returning:
            query_l.append(make_returning_clause(returning))
        queries = [' '.join(query_l)+';']
        query = ''.join(queries)
        # nicht alle "Query-Daten" dienen der Filterung (siehe oben, keys_of_both)
        query_data.update(dict_of_values)
        return query, query_data
        # -------------------------------------------- ] ... update ]

    def delete(table,  # ----------------------------- [ delete ... [
               query_data=None,
               **kwargs):
        """
        Return a simple "DELETE ..." SQL statement with placeholders
        and a values dict.

        Arguments:

          table -- name of the table (may contain the schema)
          query_data -- a dict with a disjunct set of keys
                        to restrict the rows deleted.

        Keyword-only options:

          where -- a "WHERE ..." string (which may contain placeholders)
          returning -- like supported by PostgreSQL 9.1+
          strict -- if False, unknown keyword arguments will be silently ignored;
                    if True (default), a TypeError will be raised.

        Caution: Without a WHERE criterion (whether specified as `where` or `query_data` option,
                 or a combination of both), the whole table will be deleted (like TRUNCATE, but slower and
                 without the need for the TRUNCATE permission granted);
                 there is currently nothing to prevent his!

        >>> tup1 = delete('the_table', {'status': 'done'})
        >>> tup1[0]
        'DELETE FROM the_table WHERE status = %(status)s;'
        >>> tup1[1]
        {'status': 'done'}
        """
        query_l = [replace_names('DELETE FROM %(table)s',
                                 table=table),
                   ]
        where = kwargs.get('where')
        if where and not isinstance(where, six_string_types):
            raise ValueError('where must be a string; found %(where)r'
                             % locals())
        if query_data and not where:
            where = make_where_mask(query_data)
        if where:
            query_l.append(where)
        returning = kwargs.get('returning')
        if returning:
            query_l.append(make_returning_clause(returning))
        queries = [' '.join(query_l)+';']
        query = ''.join(queries)
        return query, query_data
        # -------------------------------------------- ] ... delete ]

    def select(table,  # ----------------------------- [ select ... [
               fields='*',
               query_data=None, **kwargs):
        """
        Return a simple "SELECT ..." SQL statement with placeholders
        and a values dict.

        Arguments:

          table -- name of the table (may contain the schema)
          fields -- '*' by default; other values must not be strings
                   (but sequences of strings).
          query_data -- a dict to restrict the returned rows.

        Keyword-only options:

          where -- a "WHERE ..." string (which may contain placeholders);
                   currently necessary if some fields are both changed
                   and used in the filtering `query_data`

        There is currently no JOIN, ORDER BY etc. support whatsoever;
        if you you need this, please use views.

        >>> tup1 = select('the.table', None, {'status': 'done', 'num': 42})
        >>> tup1[0]
        'SELECT * FROM the.table WHERE num = %(num)s AND status = %(status)s;'
        >>> tup1[1]
        {'status': 'done', 'num': 42}

        >>> select('another.table')[0]
        'SELECT * FROM another.table;'

        >>> select('another.table;truncate table users')[0]
        Traceback (most recent call last):
        ...
        ValueError: Invalid chars in 'another.table;truncate table users': (' ', ';')

        """
        if fields is None:
            fields = '*'
        elif fields == '*':
            pass
        elif fields:
            liz = []
            for field in fields:
                check_name(field)
                liz.append(field)
            fields = ', '.join(liz)
        else:
            fields = '*'
        query_l = ['SELECT',
                   fields,
                   replace_names('FROM %(table)s', table=table),
                   ]
        where = kwargs.get('where')
        if where and not isinstance(where, six_string_types):
            raise ValueError('where must be a string; found %(where)r'
                             % locals())
        if where is None and query_data:
            where = make_where_mask(query_data, fields)
        if where:
            query_l.append(where)
        query = ' '.join(query_l) + ';'
        return query, query_data
        # -------------------------------------------- ] ... select ]

    return (insert, update, delete, select,
            replace_names, make_where_mask, SafeNames)


(insert, update, delete, select,
 replace_names, make_where_mask, SafeNames,
 ) = make_SqlGenerators(placeholder=pg_placeholder)
# ---------------------------------- ] ... SQL-Statements generieren ]


if __name__ == '__main__':
    import doctest
    doctest.testmod()

# vim: ts=8 sts=4 sw=4 si et
